{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polar model / Trained on MNIST-ROT / Tested on MNIST-ROT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run on GPU, can be omitted for CPU only\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get vertical cylinder effect - mentioned in paper\n",
    "def padImage(image, pixels=5):\n",
    "    bottom = image[-pixels:]\n",
    "    top = image[:pixels]\n",
    "\n",
    "    img = np.insert(image, 0, bottom, 0)\n",
    "    img = np.insert(img, len(img), top, 0)\n",
    "    #img = np.insert(img, [0], [0] * pixels, 1)\n",
    "    #img = np.insert(img, [-1], [0] * pixels, 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download amat files here: \n",
    "http://www.iro.umontreal.ca/~lisa/icml2007data/mnist_rotation_new.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume amat files are in root\n",
    "train_valid = np.loadtxt('mnist_rotation_train.amat')\n",
    "test = np.loadtxt('mnist_rotation_test.amat')\n",
    "\n",
    "X_train, y_train = train_valid[:,:-1], train_valid[:,-1]\n",
    "X_valid, y_valid = X_train[-2000:].astype(np.float32), y_train[-2000:].astype(np.int32)\n",
    "train_images, train_labels = X_train[:10000].astype(np.float32), y_train[:10000].astype(np.int32)\n",
    "test_images,  test_labels  = test[:,:-1].astype(np.float32), test[:,-1].astype(np.int32)\n",
    "\n",
    "# reshape to add alpha channel\n",
    "train_images = np.reshape(train_images, (-1, 28, 28))\n",
    "test_images = np.reshape(test_images, (-1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THE PAD HAS TO BE DONE IN THE\n",
    "### POLAR SPACE\n",
    "\n",
    "# 20 is the ceiling of (14 * sqrt(2)) - mentioned in paper\n",
    "X_train_polar = [cv.linearPolar(x, tuple(np.array(x.shape)/2), 20, cv.WARP_FILL_OUTLIERS) for x in train_images]\n",
    "X_train_polar = [padImage(x, pixels=5) for x in X_train_polar]\n",
    "X_train_polar = np.array(X_train_polar)[...,None]\n",
    "\n",
    "X_test_polar = [cv.linearPolar(x, tuple(np.array(x.shape)/2), 20, cv.WARP_FILL_OUTLIERS) for x in test_images]\n",
    "X_test_polar = [padImage(x, pixels=5) for x in X_test_polar]\n",
    "X_test_polar = np.array(X_test_polar)[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 38, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_polar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Input(shape=X_train_polar.shape[1:]))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.LayerNormalization(axis=-1, epsilon=0.001, center=True, scale=True))\n",
    "model.add(layers.Dropout(rate=0.5))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.LayerNormalization(axis=-1, epsilon=0.001, center=True, scale=True))\n",
    "model.add(layers.Dropout(rate=0.5))\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "model.add(layers.Dense(64, activation='linear'))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 38, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 19, 14, 32)        64        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 19, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 9, 7, 64)          128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 7, 256)         147712    \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 183,818\n",
      "Trainable params: 183,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/65\n",
      "313/313 [==============================] - 9s 21ms/step - loss: 2.4097 - accuracy: 0.1700 - val_loss: 1.8051 - val_accuracy: 0.3305\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.33046, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 2/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.7864 - accuracy: 0.3749 - val_loss: 1.2792 - val_accuracy: 0.5572\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.33046 to 0.55720, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 3/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.3885 - accuracy: 0.5230 - val_loss: 0.8991 - val_accuracy: 0.7022\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.55720 to 0.70222, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 4/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.0641 - accuracy: 0.6533 - val_loss: 0.7022 - val_accuracy: 0.7660\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.70222 to 0.76604, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 5/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.8804 - accuracy: 0.7203 - val_loss: 0.5525 - val_accuracy: 0.8198\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.76604 to 0.81984, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 6/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.7055 - accuracy: 0.7769 - val_loss: 0.4602 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.81984 to 0.84998, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 7/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.6154 - accuracy: 0.8038 - val_loss: 0.4031 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.84998 to 0.86980, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 8/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.5304 - accuracy: 0.8309 - val_loss: 0.3709 - val_accuracy: 0.8834\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.86980 to 0.88340, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 9/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.4918 - accuracy: 0.8422 - val_loss: 0.3287 - val_accuracy: 0.8959\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.88340 to 0.89594, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 10/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.4323 - accuracy: 0.8610 - val_loss: 0.3183 - val_accuracy: 0.9002\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.89594 to 0.90018, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 11/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.4109 - accuracy: 0.8639 - val_loss: 0.2906 - val_accuracy: 0.9086\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.90018 to 0.90856, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 12/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.3762 - accuracy: 0.8806 - val_loss: 0.2726 - val_accuracy: 0.9154\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.90856 to 0.91536, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 13/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.3383 - accuracy: 0.8944 - val_loss: 0.2643 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.91536 to 0.91726, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 14/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.3463 - accuracy: 0.8848 - val_loss: 0.2671 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91726\n",
      "Epoch 15/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.3084 - accuracy: 0.9036 - val_loss: 0.2335 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.91726 to 0.92668, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 16/65\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3020 - accuracy: 0.9036 - val_loss: 0.2297 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.92668 to 0.92828, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 17/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2879 - accuracy: 0.9105 - val_loss: 0.2344 - val_accuracy: 0.9281\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.92828\n",
      "Epoch 18/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2815 - accuracy: 0.9082 - val_loss: 0.2283 - val_accuracy: 0.9302\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.92828 to 0.93020, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 19/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2710 - accuracy: 0.9127 - val_loss: 0.2167 - val_accuracy: 0.9326\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.93020 to 0.93258, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 20/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2499 - accuracy: 0.9228 - val_loss: 0.2056 - val_accuracy: 0.9363\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.93258 to 0.93626, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 21/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2481 - accuracy: 0.9153 - val_loss: 0.2108 - val_accuracy: 0.9356\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.93626\n",
      "Epoch 22/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2390 - accuracy: 0.9202 - val_loss: 0.1972 - val_accuracy: 0.9394\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.93626 to 0.93942, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 23/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2335 - accuracy: 0.9255 - val_loss: 0.1843 - val_accuracy: 0.9445\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.93942 to 0.94448, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 24/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2347 - accuracy: 0.9288 - val_loss: 0.1890 - val_accuracy: 0.9416\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.94448\n",
      "Epoch 25/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2126 - accuracy: 0.9300 - val_loss: 0.1756 - val_accuracy: 0.9460\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.94448 to 0.94604, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 26/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2068 - accuracy: 0.9331 - val_loss: 0.1807 - val_accuracy: 0.9452\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.94604\n",
      "Epoch 27/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2050 - accuracy: 0.9365 - val_loss: 0.1874 - val_accuracy: 0.9439\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.94604\n",
      "Epoch 28/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2034 - accuracy: 0.9344 - val_loss: 0.1720 - val_accuracy: 0.9475\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.94604 to 0.94746, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 29/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1896 - accuracy: 0.9361 - val_loss: 0.1681 - val_accuracy: 0.9489\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.94746 to 0.94894, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 30/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1881 - accuracy: 0.9398 - val_loss: 0.1655 - val_accuracy: 0.9496\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.94894 to 0.94960, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 31/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1709 - accuracy: 0.9467 - val_loss: 0.1686 - val_accuracy: 0.9497\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.94960 to 0.94966, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 32/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1771 - accuracy: 0.9448 - val_loss: 0.1601 - val_accuracy: 0.9502\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.94966 to 0.95022, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 33/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1858 - accuracy: 0.9442 - val_loss: 0.1627 - val_accuracy: 0.9505\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.95022 to 0.95046, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 34/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1679 - accuracy: 0.9468 - val_loss: 0.1643 - val_accuracy: 0.9501\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.95046\n",
      "Epoch 35/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1600 - accuracy: 0.9494 - val_loss: 0.1701 - val_accuracy: 0.9486\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.95046\n",
      "Epoch 36/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1607 - accuracy: 0.9479 - val_loss: 0.1613 - val_accuracy: 0.9521\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.95046 to 0.95206, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 37/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1465 - accuracy: 0.9522 - val_loss: 0.1484 - val_accuracy: 0.9557\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.95206 to 0.95574, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 38/65\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1523 - accuracy: 0.9498 - val_loss: 0.1527 - val_accuracy: 0.9547\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.95574\n",
      "Epoch 39/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1559 - accuracy: 0.9482 - val_loss: 0.1496 - val_accuracy: 0.9553\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.95574\n",
      "Epoch 40/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1317 - accuracy: 0.9558 - val_loss: 0.1551 - val_accuracy: 0.9537\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.95574\n",
      "Epoch 41/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1360 - accuracy: 0.9533 - val_loss: 0.1480 - val_accuracy: 0.9560\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.95574 to 0.95602, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 42/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1344 - accuracy: 0.9571 - val_loss: 0.1428 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.95602 to 0.95750, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 43/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1442 - accuracy: 0.9558 - val_loss: 0.1450 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.95750\n",
      "Epoch 44/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1376 - accuracy: 0.9575 - val_loss: 0.1480 - val_accuracy: 0.9555\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.95750\n",
      "Epoch 45/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1250 - accuracy: 0.9597 - val_loss: 0.1484 - val_accuracy: 0.9559\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.95750\n",
      "Epoch 46/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1312 - accuracy: 0.9547 - val_loss: 0.1367 - val_accuracy: 0.9588\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.95750 to 0.95884, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 47/65\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1213 - accuracy: 0.9615 - val_loss: 0.1502 - val_accuracy: 0.9559\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.95884\n",
      "Epoch 48/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1245 - accuracy: 0.9577 - val_loss: 0.1381 - val_accuracy: 0.9586\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.95884\n",
      "Epoch 49/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1122 - accuracy: 0.9611 - val_loss: 0.1422 - val_accuracy: 0.9574\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.95884\n",
      "Epoch 50/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1181 - accuracy: 0.9604 - val_loss: 0.1458 - val_accuracy: 0.9576\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.95884\n",
      "Epoch 51/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1231 - accuracy: 0.9593 - val_loss: 0.1378 - val_accuracy: 0.9595\n",
      "\n",
      "Epoch 00051: val_accuracy improved from 0.95884 to 0.95946, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 52/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1094 - accuracy: 0.9633 - val_loss: 0.1449 - val_accuracy: 0.9580\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.95946\n",
      "Epoch 53/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1242 - accuracy: 0.9590 - val_loss: 0.1431 - val_accuracy: 0.9587\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.95946\n",
      "Epoch 54/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1096 - accuracy: 0.9644 - val_loss: 0.1498 - val_accuracy: 0.9569\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.95946\n",
      "Epoch 55/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1091 - accuracy: 0.9622 - val_loss: 0.1482 - val_accuracy: 0.9569\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.95946\n",
      "Epoch 56/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1033 - accuracy: 0.9666 - val_loss: 0.1334 - val_accuracy: 0.9615\n",
      "\n",
      "Epoch 00056: val_accuracy improved from 0.95946 to 0.96154, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 57/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1018 - accuracy: 0.9661 - val_loss: 0.1335 - val_accuracy: 0.9612\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.96154\n",
      "Epoch 58/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0952 - accuracy: 0.9667 - val_loss: 0.1369 - val_accuracy: 0.9599\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.96154\n",
      "Epoch 59/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1004 - accuracy: 0.9670 - val_loss: 0.1317 - val_accuracy: 0.9614\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.96154\n",
      "Epoch 60/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0889 - accuracy: 0.9707 - val_loss: 0.1422 - val_accuracy: 0.9599\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.96154\n",
      "Epoch 61/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0918 - accuracy: 0.9688 - val_loss: 0.1462 - val_accuracy: 0.9586\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.96154\n",
      "Epoch 62/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0990 - accuracy: 0.9673 - val_loss: 0.1309 - val_accuracy: 0.9624\n",
      "\n",
      "Epoch 00062: val_accuracy improved from 0.96154 to 0.96242, saving model to polar_ROT_MNIST.h5\n",
      "Epoch 63/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0889 - accuracy: 0.9667 - val_loss: 0.1377 - val_accuracy: 0.9601\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.96242\n",
      "Epoch 64/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.0955 - accuracy: 0.9697 - val_loss: 0.1331 - val_accuracy: 0.9613\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.96242\n",
      "Epoch 65/65\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.1044 - accuracy: 0.9651 - val_loss: 0.1369 - val_accuracy: 0.9615\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.96242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c470c754f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'polar_ROT_MNIST'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(name + '.h5', verbose=1, save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'], )\n",
    "model.fit(X_train_polar, train_labels, batch_size=32, epochs=65, \n",
    "          validation_data=(X_test_polar, test_labels),\n",
    "          callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.242\n"
     ]
    }
   ],
   "source": [
    "# load best epoch model\n",
    "m = tf.keras.models.load_model('polar_ROT_MNIST.h5')\n",
    "\n",
    "# Plain accuracy\n",
    "accuracy = np.mean(m.predict(X_test_polar).argmax(axis=1) == test_labels)*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction time for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.069877095222473\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "\n",
    "for _ in range(0, 50):\n",
    "    start = time.time()\n",
    "\n",
    "    model.predict(X_test_polar)\n",
    "\n",
    "    end = time.time()\n",
    "    times.append(end - start)\n",
    "\n",
    "print(np.mean(times))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.139754190444946e-05"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times) / len(X_test_polar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
