{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED NN\n",
    "\n",
    "* Code mostly from https://github.com/red-nn/RED-NN\n",
    "* Paper: https://hal-enpc.archives-ouvertes.fr/hal-02170933/document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 60,000 MNIST up-right oriented training samples and transform labels to one out of many format\n",
    "data = np.load(f'MNIST_UR_train.npz')\n",
    "x_train, y_train = data['x'], tf.keras.utils.to_categorical(data['y'], 10)\n",
    "\n",
    "# Load the 10,000 MNIST randomly rotated training samples and transform labels to one out of many format\n",
    "data = np.load('MNIST_RR_test.npz')\n",
    "x_test, y_test = data['x'], tf.keras.utils.to_categorical(data['y'], 10)\n",
    "\n",
    "\n",
    "# reshape to add alpha channel\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train, x_test = (x_train / 255.0).astype(np.float32), x_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rig2DConv(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, phi, un_rotate=True, padding='SAME', **kwargs):\n",
    "        # Non-trainable variables initialization\n",
    "        self.filters = filters\n",
    "        self.un_rotate = un_rotate\n",
    "        self.phi = phi\n",
    "        self.pad = padding\n",
    "        self.kernel_size = kernel_size\n",
    "        self.ks = tf.constant(kernel_size, dtype='float32')\n",
    "        self.angle = tf.constant(0, dtype='float32')\n",
    "        self.angle2 = tf.constant(360, dtype='float32')\n",
    "        self.ang = tf.linspace(self.angle, self.angle2, self.phi + 1)\n",
    "        self.mid = tf.constant(0.5, dtype='float32')\n",
    "        self.rds = tf.constant(np.pi / 180, dtype='float32')\n",
    "        self.center = tf.round((self.ks * self.mid) - self.mid)\n",
    "        super(Rig2DConv, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Trainable variables initialization\n",
    "        self._l = self.add_weight(name='l', shape=(self.filters,), initializer=tf.compat.v1.initializers.constant(value=0.5111867),\n",
    "                                  trainable=True, constraint=tf.keras.constraints.NonNeg())\n",
    "        self.alpha = self.add_weight(name='alpha', shape=(self.filters,), initializer=tf.compat.v1.initializers.constant(value=0.5651333),\n",
    "                                     trainable=True, constraint=tf.keras.constraints.NonNeg())\n",
    "        self.beta = self.add_weight(name='beta', shape=(self.filters,), initializer=tf.compat.v1.initializers.constant(value=1.4184482),\n",
    "                                    trainable=True,  constraint=tf.keras.constraints.NonNeg())\n",
    "        # Input size dependent variables\n",
    "        self.nf = input_shape[-1]\n",
    "        self.width = input_shape[-2]\n",
    "        self.height = input_shape[-3]\n",
    "\n",
    "        super(Rig2DConv, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        # Generate a set of coordinates\n",
    "        d = tf.range(self.ks)\n",
    "        x_coord, y_coord = tf.meshgrid(d, d)\n",
    "        x_coord = tf.cast(x_coord, dtype=\"float32\") - self.center\n",
    "        y_coord = tf.cast(y_coord, dtype=\"float32\") - self.center\n",
    "\n",
    "        # Horizontal basis filter\n",
    "        arx = tf.math.divide((-2 * self.alpha[0] * tf.square(self._l[0]) * x_coord), np.pi) * tf.exp(\n",
    "            -self._l[0] * ((self.alpha[0] * tf.square(x_coord)) + (self.beta[0] * tf.square(y_coord))))\n",
    "\n",
    "        # Vertical basis filter\n",
    "        ary = tf.math.divide((-2 * self.beta[0] * tf.square(self._l[0]) * y_coord), np.pi) * tf.exp(\n",
    "            -self._l[0] * ((self.alpha[0] * tf.square(x_coord)) + (self.beta[0] * tf.square(y_coord))))\n",
    "\n",
    "        arx = tf.expand_dims(arx, axis=-1)\n",
    "        ary = tf.expand_dims(ary, axis=-1)\n",
    "\n",
    "        # First filter generation\n",
    "        ar = (tf.cos(self.ang[0] * self.rds) * arx) + (tf.sin(self.ang[0] * self.rds) * ary)\n",
    "        # Convolve input with first generated filter\n",
    "        par1 = tf.nn.conv2d(input=x, filters=tf.reshape(ar, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1), padding=self.pad)\n",
    "        # Rotation compensation to get translational feature space\n",
    "        par2 = tfa.image.rotate(par1, self.ang[0] * self.rds, interpolation='BILINEAR')\n",
    "\n",
    "        # Second filter generation\n",
    "        ar1 = (tf.cos(self.ang[1] * self.rds) * arx) + (tf.sin(self.ang[1] * self.rds) * ary)\n",
    "        # Convolve input with second generated filter\n",
    "        par3 = tf.nn.conv2d(input=x, filters=tf.reshape(ar1, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1), padding=self.pad)\n",
    "        # Rotation compensation to get translational feature space\n",
    "        par4 = tfa.image.rotate(par3, self.ang[1] * self.rds, interpolation='BILINEAR')\n",
    "\n",
    "        if self.un_rotate:\n",
    "            out = tf.concat([par2, par4], axis=3)\n",
    "        else:\n",
    "            out = tf.concat([par1, par3], axis=3)\n",
    "\n",
    "        # Apply same process from filters up to Phi\n",
    "        for aa in range(2, self.phi):\n",
    "            ar = (tf.cos(self.ang[aa] * self.rds) * arx) + (tf.sin(self.ang[aa] * self.rds) * ary)\n",
    "            partial = tf.nn.conv2d(input=x, filters=tf.reshape(ar, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1),\n",
    "                                   padding=self.pad)\n",
    "            partial2 = tfa.image.rotate(partial, self.ang[aa] * self.rds, interpolation='BILINEAR')\n",
    "            if self.un_rotate:\n",
    "                out = tf.concat([out, partial2], axis=3)\n",
    "            else:\n",
    "                out = tf.concat([out, partial], axis=3)\n",
    "        out_f1 = tf.reshape(out, shape=(-1, self.height, self.width, self.phi, 1))\n",
    "        out_f1 = tf.transpose(a=out_f1, perm=(0, 3, 1, 2, 4))\n",
    "\n",
    "        # If only one filter ensemble is used return this\n",
    "        if self.filters == 1:\n",
    "            return out_f1\n",
    "        # If more ensembles are required do the same\n",
    "        arx = tf.math.divide((-2 * self.alpha[1] * tf.square(self._l[1]) * x_coord), np.pi) * tf.exp(\n",
    "            -self._l[1] * ((self.alpha[1] * tf.square(x_coord)) + (self.beta[1] * tf.square(y_coord))))\n",
    "\n",
    "        ary = tf.math.divide((-2 * self.beta[1] * tf.square(self._l[1]) * y_coord), np.pi) * tf.exp(\n",
    "            -self._l[1] * ((self.alpha[1] * tf.square(x_coord)) + (self.beta[1] * tf.square(y_coord))))\n",
    "\n",
    "        arx = tf.expand_dims(arx, axis=-1)\n",
    "        ary = tf.expand_dims(ary, axis=-1)\n",
    "\n",
    "        ar = (tf.cos(self.ang[0] * self.rds) * arx) + (tf.sin(self.ang[0] * self.rds) * ary)\n",
    "        par1 = tf.nn.conv2d(input=x, filters=tf.reshape(ar, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1), padding=self.pad)\n",
    "        par2 = tfa.image.rotate(par1, self.ang[0] * self.rds, interpolation='BILINEAR')\n",
    "\n",
    "        ar1 = (tf.cos(self.ang[1] * self.rds) * arx) + (tf.sin(self.ang[1] * self.rds) * ary)\n",
    "        par3 = tf.nn.conv2d(input=x, filters=tf.reshape(ar1, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1), padding=self.pad)\n",
    "        par4 = tfa.image.rotate(par3, self.ang[1] * self.rds, interpolation='BILINEAR')\n",
    "\n",
    "        if self.un_rotate:\n",
    "            out = tf.concat([par2, par4], axis=3)\n",
    "        else:\n",
    "            out = tf.concat([par1, par3], axis=3)\n",
    "\n",
    "        for aa in range(2, self.phi):\n",
    "            ar = (tf.cos(self.ang[aa] * self.rds) * arx) + (tf.sin(self.ang[aa] * self.rds) * ary)\n",
    "            partial = tf.nn.conv2d(input=x, filters=tf.reshape(ar, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1),\n",
    "                                   padding=self.pad)\n",
    "            partial2 = tfa.image.rotate(partial, self.ang[aa] * self.rds, interpolation='BILINEAR')\n",
    "            if self.un_rotate:\n",
    "                out = tf.concat([out, partial2], axis=3)\n",
    "            else:\n",
    "                out = tf.concat([out, partial], axis=3)\n",
    "        out_f2 = tf.reshape(out, shape=(-1, self.height, self.width, self.phi, 1))\n",
    "        out_f2 = tf.transpose(a=out_f2, perm=(0, 3, 1, 2, 4))\n",
    "\n",
    "        out_final = tf.concat([out_f1, out_f2], axis=4)\n",
    "\n",
    "        for bb in range(2, self.filters):\n",
    "\n",
    "            arx = tf.math.divide((-2 * self.alpha[bb] * tf.square(self._l[bb]) * x_coord), np.pi) * tf.exp(\n",
    "                -self._l[bb] * ((self.alpha[bb] * tf.square(x_coord)) + (self.beta[bb] * tf.square(y_coord))))\n",
    "\n",
    "            ary = tf.math.divide((-2 * self.beta[bb] * tf.square(self._l[bb]) * y_coord), np.pi) * tf.exp(\n",
    "                -self._l[bb] * ((self.alpha[bb] * tf.square(x_coord)) + (self.beta[bb] * tf.square(y_coord))))\n",
    "\n",
    "            arx = tf.expand_dims(arx, axis=-1)\n",
    "            ary = tf.expand_dims(ary, axis=-1)\n",
    "\n",
    "            ar = (tf.cos(self.ang[0] * self.rds) * arx) + (tf.sin(self.ang[0] * self.rds) * ary)\n",
    "            par1 = tf.nn.conv2d(input=x, filters=tf.reshape(ar, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1),\n",
    "                                padding=self.pad)\n",
    "            par2 = tfa.image.rotate(par1, self.ang[0] * self.rds, interpolation='BILINEAR')\n",
    "\n",
    "            ar1 = (tf.cos(self.ang[1] * self.rds) * arx) + (tf.sin(self.ang[1] * self.rds) * ary)\n",
    "            par3 = tf.nn.conv2d(input=x, filters=tf.reshape(ar1, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1),\n",
    "                                padding=self.pad)\n",
    "            par4 = tfa.image.rotate(par3, self.ang[1] * self.rds, interpolation='BILINEAR')\n",
    "\n",
    "            if self.un_rotate:\n",
    "                out = tf.concat([par2, par4], axis=3)\n",
    "            else:\n",
    "                out = tf.concat([par1, par3], axis=3)\n",
    "\n",
    "            for aa in range(2, self.phi):\n",
    "                ar = (tf.cos(self.ang[aa] * self.rds) * arx) + (tf.sin(self.ang[aa] * self.rds) * ary)\n",
    "                partial = tf.nn.conv2d(input=x, filters=tf.reshape(ar, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1),\n",
    "                                       padding=self.pad)\n",
    "                partial2 = tfa.image.rotate(partial, self.ang[aa] * self.rds, interpolation='BILINEAR')\n",
    "                if self.un_rotate:\n",
    "                    out = tf.concat([out, partial2], axis=3)\n",
    "                else:\n",
    "                    out = tf.concat([out, partial], axis=3)\n",
    "            out_fn = tf.reshape(out, shape=(-1, self.height, self.width, self.phi, 1))\n",
    "            out_fn = tf.transpose(a=out_fn, perm=(0, 3, 1, 2, 4))\n",
    "\n",
    "            out_final = tf.concat([out_final, out_fn], axis=4)\n",
    "\n",
    "        return out_final\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(Rig2DConv, self).get_config()\n",
    "        base_config['filters'] = self.filters\n",
    "        base_config['kernel_size'] = self.kernel_size\n",
    "        base_config['phi'] = self.phi\n",
    "        return base_config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A cyclic convolution can be implemented with a linear convolution over a periodically padded feature space\n",
    "class Periodic_Pad(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Periodic_Pad, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Periodic_Pad, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.concat([inputs, inputs], axis=1)\n",
    "        return x[:, :-1, :, :, :]\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(Periodic_Pad, self).get_config()\n",
    "        return base_config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image size\n",
    "ROWS = 28\n",
    "COLS = 28\n",
    "\n",
    "# Angular samples (PHI)\n",
    "PHI = 16\n",
    "\n",
    "# Number of filters for each convolution stage\n",
    "CONV1_F = 16\n",
    "CONV2_F = 16\n",
    "CONV3_F = 16\n",
    "\n",
    "# Model definition\n",
    "in_shape = tf.keras.Input(shape=(ROWS, COLS, 1), name=\"Input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Rig2DConv(filters=1, kernel_size=10, phi=PHI, un_rotate=True, name=\"Rig\")(in_shape)\n",
    "# Periodic padding for cyclic convolution\n",
    "x = Periodic_Pad()(x)\n",
    "\n",
    "# 3 stacked convolutional predictors with batch normalization\n",
    "x = tf.keras.layers.BatchNormalization(name=\"BN1\")(x)\n",
    "x = tf.keras.layers.Conv3D(CONV1_F, kernel_size=(1, 5, 5), activation='relu', name=\"CONV1\")(x)\n",
    "x = tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), name=\"MP1\")(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization(name=\"BN2\")(x)\n",
    "x = tf.keras.layers.Conv3D(CONV2_F, kernel_size=(1, 3, 3), activation='relu', name=\"CONV2\")(x)\n",
    "x = tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), name=\"MP2\")(x)\n",
    "\n",
    "# Translational convolution over the depth axis of the feature space\n",
    "x = tf.keras.layers.BatchNormalization(name=\"BN3\")(x)\n",
    "x = tf.keras.layers.Conv3D(CONV3_F, kernel_size=(PHI, 3, 3), activation='relu', name=\"CONV3\")(x)\n",
    "\n",
    "# Dense hidden layer predictor\n",
    "x = tf.keras.layers.Reshape((PHI, 3*3*CONV3_F))(x)\n",
    "x = tf.keras.layers.Dense(30, activation='relu', name=\"Hidden_Dense\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(10, activation='softmax', name=\"Output_table\")(x)\n",
    "\n",
    "# Maxpooling applied to the columns results in the predicted class\n",
    "number = tf.keras.layers.GlobalMaxPooling1D(name=\"number\")(x)\n",
    "x_permuted = tf.keras.layers.Permute((2, 1))(x)\n",
    "# Maxpooling applied to the rows results in the predicted angle row index\n",
    "angle = tf.keras.layers.GlobalMaxPooling1D(name=\"angle\")(x_permuted)\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "model = tf.keras.Model(inputs=in_shape, outputs=number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "Rig (Rig2DConv)              (None, 16, 28, 28, 1)     3         \n",
      "_________________________________________________________________\n",
      "periodic__pad (Periodic_Pad) (None, 31, 28, 28, 1)     0         \n",
      "_________________________________________________________________\n",
      "BN1 (BatchNormalization)     (None, 31, 28, 28, 1)     4         \n",
      "_________________________________________________________________\n",
      "CONV1 (Conv3D)               (None, 31, 24, 24, 16)    416       \n",
      "_________________________________________________________________\n",
      "MP1 (MaxPooling3D)           (None, 31, 12, 12, 16)    0         \n",
      "_________________________________________________________________\n",
      "BN2 (BatchNormalization)     (None, 31, 12, 12, 16)    64        \n",
      "_________________________________________________________________\n",
      "CONV2 (Conv3D)               (None, 31, 10, 10, 16)    2320      \n",
      "_________________________________________________________________\n",
      "MP2 (MaxPooling3D)           (None, 31, 5, 5, 16)      0         \n",
      "_________________________________________________________________\n",
      "BN3 (BatchNormalization)     (None, 31, 5, 5, 16)      64        \n",
      "_________________________________________________________________\n",
      "CONV3 (Conv3D)               (None, 16, 3, 3, 16)      36880     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 144)           0         \n",
      "_________________________________________________________________\n",
      "Hidden_Dense (Dense)         (None, 16, 30)            4350      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 30)            0         \n",
      "_________________________________________________________________\n",
      "Output_table (Dense)         (None, 16, 10)            310       \n",
      "_________________________________________________________________\n",
      "number (GlobalMaxPooling1D)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 44,411\n",
      "Trainable params: 44,345\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training section\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
     ]
    }
   ],
   "source": [
    "name = f'URT_REDNN_v2_{PHI}'\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(name + '.h5', verbose=1, save_best_only=True, monitor='val_loss', mode='min')\n",
    "tensorboardcb = tf.keras.callbacks.TensorBoard(log_dir=os.path.join('tests', name), write_images=True, write_grads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 1718s 4s/step - loss: 1.2144 - accuracy: 0.7803 - val_loss: 1.0081 - val_accuracy: 0.8257\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.00813, saving model to URT_REDNN_v2_16.h5\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 1705s 4s/step - loss: 0.7045 - accuracy: 0.9630 - val_loss: 0.8335 - val_accuracy: 0.8919\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.00813 to 0.83353, saving model to URT_REDNN_v2_16.h5\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 1706s 4s/step - loss: 0.6743 - accuracy: 0.9722 - val_loss: 0.8034 - val_accuracy: 0.8997\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.83353 to 0.80335, saving model to URT_REDNN_v2_16.h5\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 1705s 4s/step - loss: 0.6638 - accuracy: 0.9754 - val_loss: 0.9030 - val_accuracy: 0.8684\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.80335\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 1705s 4s/step - loss: 0.6555 - accuracy: 0.9783 - val_loss: 0.8227 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.80335\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 1704s 4s/step - loss: 0.6521 - accuracy: 0.9795 - val_loss: 0.8121 - val_accuracy: 0.8842\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.80335\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 1698s 4s/step - loss: 0.6464 - accuracy: 0.9818 - val_loss: 0.8261 - val_accuracy: 0.8822\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.80335\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 1705s 4s/step - loss: 0.6424 - accuracy: 0.9821 - val_loss: 0.8432 - val_accuracy: 0.8724\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.80335\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 1705s 4s/step - loss: 0.6338 - accuracy: 0.9864 - val_loss: 0.8161 - val_accuracy: 0.8846\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.80335\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 1701s 4s/step - loss: 0.6300 - accuracy: 0.9871 - val_loss: 0.8176 - val_accuracy: 0.8837\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.80335\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 1699s 4s/step - loss: 0.6281 - accuracy: 0.9878 - val_loss: 0.8550 - val_accuracy: 0.8597\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.80335\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 1705s 4s/step - loss: 0.6268 - accuracy: 0.9887 - val_loss: 0.8582 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.80335\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 1705s 4s/step - loss: 0.6284 - accuracy: 0.9880 - val_loss: 0.8379 - val_accuracy: 0.8681\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.80335\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 1705s 4s/step - loss: 0.6214 - accuracy: 0.9903 - val_loss: 0.8528 - val_accuracy: 0.8599\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.80335\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 1704s 4s/step - loss: 0.6197 - accuracy: 0.9909 - val_loss: 0.8257 - val_accuracy: 0.8735\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.80335\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 1705s 4s/step - loss: 0.6206 - accuracy: 0.9907 - val_loss: 0.8401 - val_accuracy: 0.8646\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.80335\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 1705s 4s/step - loss: 0.6193 - accuracy: 0.9912 - val_loss: 0.8438 - val_accuracy: 0.8630\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.80335\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 1706s 4s/step - loss: 0.6184 - accuracy: 0.9919 - val_loss: 0.8446 - val_accuracy: 0.8666\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.80335\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 1705s 4s/step - loss: 0.6164 - accuracy: 0.9918 - val_loss: 0.8247 - val_accuracy: 0.8735\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.80335\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 1701s 4s/step - loss: 0.6176 - accuracy: 0.9929 - val_loss: 0.8462 - val_accuracy: 0.8646\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.80335\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 1700s 4s/step - loss: 0.6174 - accuracy: 0.9922 - val_loss: 0.8529 - val_accuracy: 0.8610\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.80335\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 1700s 4s/step - loss: 0.6156 - accuracy: 0.9928 - val_loss: 0.8310 - val_accuracy: 0.8697\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.80335\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 1700s 4s/step - loss: 0.6160 - accuracy: 0.9921 - val_loss: 0.8329 - val_accuracy: 0.8714\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.80335\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 1700s 4s/step - loss: 0.6168 - accuracy: 0.9930 - val_loss: 0.8430 - val_accuracy: 0.8645\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.80335\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 1700s 4s/step - loss: 0.6154 - accuracy: 0.9922 - val_loss: 0.8491 - val_accuracy: 0.8628\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.80335\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 1701s 4s/step - loss: 0.6142 - accuracy: 0.9931 - val_loss: 0.8396 - val_accuracy: 0.8674\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.80335\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 1701s 4s/step - loss: 0.6139 - accuracy: 0.9931 - val_loss: 0.8410 - val_accuracy: 0.8651\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.80335\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 1701s 4s/step - loss: 0.6144 - accuracy: 0.9933 - val_loss: 0.8341 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.80335\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 1700s 4s/step - loss: 0.6137 - accuracy: 0.9934 - val_loss: 0.8375 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.80335\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 1700s 4s/step - loss: 0.6141 - accuracy: 0.9927 - val_loss: 0.8416 - val_accuracy: 0.8665\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.80335\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 1701s 4s/step - loss: 0.6123 - accuracy: 0.9933 - val_loss: 0.8359 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.80335\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 1701s 4s/step - loss: 0.6137 - accuracy: 0.9934 - val_loss: 0.8417 - val_accuracy: 0.8657\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.80335\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 1701s 4s/step - loss: 0.6138 - accuracy: 0.9928 - val_loss: 0.8379 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.80335\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 1701s 4s/step - loss: 0.6120 - accuracy: 0.9939 - val_loss: 0.8400 - val_accuracy: 0.8666\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.80335\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 1701s 4s/step - loss: 0.6113 - accuracy: 0.9937 - val_loss: 0.8412 - val_accuracy: 0.8659\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.80335\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 1701s 4s/step - loss: 0.6132 - accuracy: 0.9938 - val_loss: 0.8418 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.80335\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 1702s 4s/step - loss: 0.6116 - accuracy: 0.9938 - val_loss: 0.8346 - val_accuracy: 0.8699\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.80335\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 1703s 4s/step - loss: 0.6136 - accuracy: 0.9931 - val_loss: 0.8385 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.80335\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 1700s 4s/step - loss: 0.6132 - accuracy: 0.9939 - val_loss: 0.8383 - val_accuracy: 0.8674\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.80335\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - 1700s 4s/step - loss: 0.6114 - accuracy: 0.9938 - val_loss: 0.8406 - val_accuracy: 0.8663\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.80335\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - 1701s 4s/step - loss: 0.6129 - accuracy: 0.9939 - val_loss: 0.8412 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.80335\n",
      "Epoch 42/50\n",
      "469/469 [==============================] - 1702s 4s/step - loss: 0.6111 - accuracy: 0.9941 - val_loss: 0.8405 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.80335\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - 1702s 4s/step - loss: 0.6126 - accuracy: 0.9936 - val_loss: 0.8380 - val_accuracy: 0.8668\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.80335\n",
      "Epoch 44/50\n",
      "469/469 [==============================] - 1702s 4s/step - loss: 0.6119 - accuracy: 0.9934 - val_loss: 0.8393 - val_accuracy: 0.8668\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.80335\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - 1702s 4s/step - loss: 0.6129 - accuracy: 0.9939 - val_loss: 0.8384 - val_accuracy: 0.8670\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.80335\n",
      "Epoch 46/50\n",
      "469/469 [==============================] - 1703s 4s/step - loss: 0.6125 - accuracy: 0.9936 - val_loss: 0.8415 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.80335\n",
      "Epoch 47/50\n",
      "469/469 [==============================] - 1703s 4s/step - loss: 0.6112 - accuracy: 0.9938 - val_loss: 0.8400 - val_accuracy: 0.8668\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.80335\n",
      "Epoch 48/50\n",
      "469/469 [==============================] - 1702s 4s/step - loss: 0.6129 - accuracy: 0.9938 - val_loss: 0.8418 - val_accuracy: 0.8648\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.80335\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - 1703s 4s/step - loss: 0.6131 - accuracy: 0.9939 - val_loss: 0.8401 - val_accuracy: 0.8659\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.80335\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - 1704s 4s/step - loss: 0.6118 - accuracy: 0.9940 - val_loss: 0.8405 - val_accuracy: 0.8659\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.80335\n",
      "INFO:tensorflow:Assets written to: models/RED_NN_v2_50\\assets\n"
     ]
    }
   ],
   "source": [
    "model_path = 'models/RED_NN_v2_50'\n",
    "#x_test_r = [tfa.image.rotate(x, np.random.uniform(-np.pi/2., np.pi/2.)).numpy() for x in x_test]\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    history = None\n",
    "else:\n",
    "    history = model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[reduce_lr, checkpoint, tensorboardcb])\n",
    "    \n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if history:\n",
    "    train_acc = history.history['accuracy'][-1]\n",
    "    val_acc = history.history['val_accuracy'][-1]\n",
    "    plt.plot(history.history['accuracy'], label=f'accuracy = {train_acc:.2f}')\n",
    "    plt.plot(history.history['val_accuracy'], label = f'val_accuracy = {val_acc:.2f}')\n",
    "    plt.title('O/O CIFAR10 Training History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0.5, 1])\n",
    "    plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on rotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 28s - loss: 0.8405 - accuracy: 0.8659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8404873013496399, 0.8658999800682068]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Their results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "Rig (Rig2DConv)              (None, 16, 28, 28, 1)     3         \n",
      "_________________________________________________________________\n",
      "periodic__pad_75 (Periodic_P (None, 31, 28, 28, 1)     0         \n",
      "_________________________________________________________________\n",
      "BN1 (BatchNormalization)     (None, 31, 28, 28, 1)     4         \n",
      "_________________________________________________________________\n",
      "CONV1 (Conv3D)               (None, 31, 24, 24, 16)    416       \n",
      "_________________________________________________________________\n",
      "MP1 (MaxPooling3D)           (None, 31, 12, 12, 16)    0         \n",
      "_________________________________________________________________\n",
      "BN2 (BatchNormalization)     (None, 31, 12, 12, 16)    64        \n",
      "_________________________________________________________________\n",
      "CONV2 (Conv3D)               (None, 31, 10, 10, 16)    2320      \n",
      "_________________________________________________________________\n",
      "MP2 (MaxPooling3D)           (None, 31, 5, 5, 16)      0         \n",
      "_________________________________________________________________\n",
      "BN3 (BatchNormalization)     (None, 31, 5, 5, 16)      64        \n",
      "_________________________________________________________________\n",
      "CONV3 (Conv3D)               (None, 16, 3, 3, 16)      36880     \n",
      "_________________________________________________________________\n",
      "reshape_75 (Reshape)         (None, 16, 144)           0         \n",
      "_________________________________________________________________\n",
      "Hidden_Dense (Dense)         (None, 16, 30)            4350      \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 16, 30)            0         \n",
      "_________________________________________________________________\n",
      "Output_table (Dense)         (None, 16, 10)            310       \n",
      "_________________________________________________________________\n",
      "number (GlobalMaxPooling1D)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 44,411\n",
      "Trainable params: 44,345\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 31s 93ms/step - loss: 0.5962 - accuracy: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5962042212486267, 0.9857000112533569]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = tf.keras.models.load_model('RRT_REDNN_16.h5', custom_objects={'Rig2DConv': Rig2DConv,\n",
    "                                                                             'Periodic_Pad': Periodic_Pad})\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "model2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "Rig (Rig2DConv)              (None, 16, 28, 28, 1)     3         \n",
      "_________________________________________________________________\n",
      "periodic__pad_33 (Periodic_P (None, 31, 28, 28, 1)     0         \n",
      "_________________________________________________________________\n",
      "BN1 (BatchNormalization)     (None, 31, 28, 28, 1)     4         \n",
      "_________________________________________________________________\n",
      "CONV1 (Conv3D)               (None, 31, 24, 24, 16)    416       \n",
      "_________________________________________________________________\n",
      "MP1 (MaxPooling3D)           (None, 31, 12, 12, 16)    0         \n",
      "_________________________________________________________________\n",
      "BN2 (BatchNormalization)     (None, 31, 12, 12, 16)    64        \n",
      "_________________________________________________________________\n",
      "CONV2 (Conv3D)               (None, 31, 10, 10, 16)    2320      \n",
      "_________________________________________________________________\n",
      "MP2 (MaxPooling3D)           (None, 31, 5, 5, 16)      0         \n",
      "_________________________________________________________________\n",
      "BN3 (BatchNormalization)     (None, 31, 5, 5, 16)      64        \n",
      "_________________________________________________________________\n",
      "CONV3 (Conv3D)               (None, 16, 3, 3, 16)      36880     \n",
      "_________________________________________________________________\n",
      "reshape_33 (Reshape)         (None, 16, 144)           0         \n",
      "_________________________________________________________________\n",
      "Hidden_Dense (Dense)         (None, 16, 30)            4350      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 16, 30)            0         \n",
      "_________________________________________________________________\n",
      "Output_table (Dense)         (None, 16, 10)            310       \n",
      "_________________________________________________________________\n",
      "number (GlobalMaxPooling1D)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 44,411\n",
      "Trainable params: 44,345\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 32s 97ms/step - loss: 0.7012 - accuracy: 0.9751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7012384533882141, 0.9750999808311462]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = tf.keras.models.load_model('URT_REDNN_16_orig.h5', custom_objects={'Rig2DConv': Rig2DConv,\n",
    "                                                                             'Periodic_Pad': Periodic_Pad})\n",
    "\n",
    "model3.summary()\n",
    "\n",
    "model3.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
