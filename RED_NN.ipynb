{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED NN\n",
    "\n",
    "* Code mostly from https://github.com/red-nn/RED-NN\n",
    "* Paper: https://hal-enpc.archives-ouvertes.fr/hal-02170933/document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train, x_test = (x_train / 255.0).astype(np.float32), x_test.astype(np.float32) / 255.0\n",
    "\n",
    "\n",
    "# Reshape into (amount, 10)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "# reshape to add alpha channel\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rig2DConv(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, phi, un_rotate=True, padding='SAME', **kwargs):\n",
    "        # Non-trainable variables initialization\n",
    "        self.filters = filters\n",
    "        self.un_rotate = un_rotate\n",
    "        self.phi = phi\n",
    "        self.pad = padding\n",
    "        self.kernel_size = kernel_size\n",
    "        self.ks = tf.constant(kernel_size, dtype='float32')\n",
    "        self.angle = tf.constant(0, dtype='float32')\n",
    "        self.angle2 = tf.constant(360, dtype='float32')\n",
    "        self.ang = tf.linspace(self.angle, self.angle2, self.phi + 1)\n",
    "        self.mid = tf.constant(0.5, dtype='float32')\n",
    "        self.rds = tf.constant(np.pi / 180, dtype='float32')\n",
    "        self.center = tf.round((self.ks * self.mid) - self.mid)\n",
    "        super(Rig2DConv, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Trainable variables initialization\n",
    "        self._l = self.add_weight(name='l', shape=(self.filters,), initializer=tf.compat.v1.initializers.constant(value=0.5111867),\n",
    "                                  trainable=True, constraint=tf.keras.constraints.NonNeg())\n",
    "        self.alpha = self.add_weight(name='alpha', shape=(self.filters,), initializer=tf.compat.v1.initializers.constant(value=0.5651333),\n",
    "                                     trainable=True, constraint=tf.keras.constraints.NonNeg())\n",
    "        self.beta = self.add_weight(name='beta', shape=(self.filters,), initializer=tf.compat.v1.initializers.constant(value=1.4184482),\n",
    "                                    trainable=True,  constraint=tf.keras.constraints.NonNeg())\n",
    "        # Input size dependent variables\n",
    "        self.nf = input_shape[-1]\n",
    "        self.width = input_shape[-2]\n",
    "        self.height = input_shape[-3]\n",
    "\n",
    "        super(Rig2DConv, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        # Generate a set of coordinates\n",
    "        d = tf.range(self.ks)\n",
    "        x_coord, y_coord = tf.meshgrid(d, d)\n",
    "        x_coord = tf.cast(x_coord, dtype=\"float32\") - self.center\n",
    "        y_coord = tf.cast(y_coord, dtype=\"float32\") - self.center\n",
    "\n",
    "        # Horizontal basis filter\n",
    "        arx = tf.math.divide((-2 * self.alpha[0] * tf.square(self._l[0]) * x_coord), np.pi) * tf.exp(\n",
    "            -self._l[0] * ((self.alpha[0] * tf.square(x_coord)) + (self.beta[0] * tf.square(y_coord))))\n",
    "\n",
    "        # Vertical basis filter\n",
    "        ary = tf.math.divide((-2 * self.beta[0] * tf.square(self._l[0]) * y_coord), np.pi) * tf.exp(\n",
    "            -self._l[0] * ((self.alpha[0] * tf.square(x_coord)) + (self.beta[0] * tf.square(y_coord))))\n",
    "\n",
    "        arx = tf.expand_dims(arx, axis=-1)\n",
    "        ary = tf.expand_dims(ary, axis=-1)\n",
    "\n",
    "        # First filter generation\n",
    "        ar = (tf.cos(self.ang[0] * self.rds) * arx) + (tf.sin(self.ang[0] * self.rds) * ary)\n",
    "        # Convolve input with first generated filter\n",
    "        par1 = tf.nn.conv2d(input=x, filters=tf.reshape(ar, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1), padding=self.pad)\n",
    "        # Rotation compensation to get translational feature space\n",
    "        par2 = tfa.image.rotate(par1, self.ang[0] * self.rds, interpolation='BILINEAR')\n",
    "\n",
    "        # Second filter generation\n",
    "        ar1 = (tf.cos(self.ang[1] * self.rds) * arx) + (tf.sin(self.ang[1] * self.rds) * ary)\n",
    "        # Convolve input with second generated filter\n",
    "        par3 = tf.nn.conv2d(input=x, filters=tf.reshape(ar1, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1), padding=self.pad)\n",
    "        # Rotation compensation to get translational feature space\n",
    "        par4 = tfa.image.rotate(par3, self.ang[1] * self.rds, interpolation='BILINEAR')\n",
    "\n",
    "        if self.un_rotate:\n",
    "            out = tf.concat([par2, par4], axis=3)\n",
    "        else:\n",
    "            out = tf.concat([par1, par3], axis=3)\n",
    "\n",
    "        # Apply same process from filters up to Phi\n",
    "        for aa in range(2, self.phi):\n",
    "            ar = (tf.cos(self.ang[aa] * self.rds) * arx) + (tf.sin(self.ang[aa] * self.rds) * ary)\n",
    "            partial = tf.nn.conv2d(input=x, filters=tf.reshape(ar, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1),\n",
    "                                   padding=self.pad)\n",
    "            partial2 = tfa.image.rotate(partial, self.ang[aa] * self.rds, interpolation='BILINEAR')\n",
    "            if self.un_rotate:\n",
    "                out = tf.concat([out, partial2], axis=3)\n",
    "            else:\n",
    "                out = tf.concat([out, partial], axis=3)\n",
    "        out_f1 = tf.reshape(out, shape=(-1, self.height, self.width, self.phi, 1))\n",
    "        out_f1 = tf.transpose(a=out_f1, perm=(0, 3, 1, 2, 4))\n",
    "\n",
    "        # If only one filter ensemble is used return this\n",
    "        if self.filters == 1:\n",
    "            return out_f1\n",
    "        # If more ensembles are required do the same\n",
    "        arx = tf.math.divide((-2 * self.alpha[1] * tf.square(self._l[1]) * x_coord), np.pi) * tf.exp(\n",
    "            -self._l[1] * ((self.alpha[1] * tf.square(x_coord)) + (self.beta[1] * tf.square(y_coord))))\n",
    "\n",
    "        ary = tf.math.divide((-2 * self.beta[1] * tf.square(self._l[1]) * y_coord), np.pi) * tf.exp(\n",
    "            -self._l[1] * ((self.alpha[1] * tf.square(x_coord)) + (self.beta[1] * tf.square(y_coord))))\n",
    "\n",
    "        arx = tf.expand_dims(arx, axis=-1)\n",
    "        ary = tf.expand_dims(ary, axis=-1)\n",
    "\n",
    "        ar = (tf.cos(self.ang[0] * self.rds) * arx) + (tf.sin(self.ang[0] * self.rds) * ary)\n",
    "        par1 = tf.nn.conv2d(input=x, filters=tf.reshape(ar, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1), padding=self.pad)\n",
    "        par2 = tfa.image.rotate(par1, self.ang[0] * self.rds, interpolation='BILINEAR')\n",
    "\n",
    "        ar1 = (tf.cos(self.ang[1] * self.rds) * arx) + (tf.sin(self.ang[1] * self.rds) * ary)\n",
    "        par3 = tf.nn.conv2d(input=x, filters=tf.reshape(ar1, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1), padding=self.pad)\n",
    "        par4 = tfa.image.rotate(par3, self.ang[1] * self.rds, interpolation='BILINEAR')\n",
    "\n",
    "        if self.un_rotate:\n",
    "            out = tf.concat([par2, par4], axis=3)\n",
    "        else:\n",
    "            out = tf.concat([par1, par3], axis=3)\n",
    "\n",
    "        for aa in range(2, self.phi):\n",
    "            ar = (tf.cos(self.ang[aa] * self.rds) * arx) + (tf.sin(self.ang[aa] * self.rds) * ary)\n",
    "            partial = tf.nn.conv2d(input=x, filters=tf.reshape(ar, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1),\n",
    "                                   padding=self.pad)\n",
    "            partial2 = tfa.image.rotate(partial, self.ang[aa] * self.rds, interpolation='BILINEAR')\n",
    "            if self.un_rotate:\n",
    "                out = tf.concat([out, partial2], axis=3)\n",
    "            else:\n",
    "                out = tf.concat([out, partial], axis=3)\n",
    "        out_f2 = tf.reshape(out, shape=(-1, self.height, self.width, self.phi, 1))\n",
    "        out_f2 = tf.transpose(a=out_f2, perm=(0, 3, 1, 2, 4))\n",
    "\n",
    "        out_final = tf.concat([out_f1, out_f2], axis=4)\n",
    "\n",
    "        for bb in range(2, self.filters):\n",
    "\n",
    "            arx = tf.math.divide((-2 * self.alpha[bb] * tf.square(self._l[bb]) * x_coord), np.pi) * tf.exp(\n",
    "                -self._l[bb] * ((self.alpha[bb] * tf.square(x_coord)) + (self.beta[bb] * tf.square(y_coord))))\n",
    "\n",
    "            ary = tf.math.divide((-2 * self.beta[bb] * tf.square(self._l[bb]) * y_coord), np.pi) * tf.exp(\n",
    "                -self._l[bb] * ((self.alpha[bb] * tf.square(x_coord)) + (self.beta[bb] * tf.square(y_coord))))\n",
    "\n",
    "            arx = tf.expand_dims(arx, axis=-1)\n",
    "            ary = tf.expand_dims(ary, axis=-1)\n",
    "\n",
    "            ar = (tf.cos(self.ang[0] * self.rds) * arx) + (tf.sin(self.ang[0] * self.rds) * ary)\n",
    "            par1 = tf.nn.conv2d(input=x, filters=tf.reshape(ar, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1),\n",
    "                                padding=self.pad)\n",
    "            par2 = tfa.image.rotate(par1, self.ang[0] * self.rds, interpolation='BILINEAR')\n",
    "\n",
    "            ar1 = (tf.cos(self.ang[1] * self.rds) * arx) + (tf.sin(self.ang[1] * self.rds) * ary)\n",
    "            par3 = tf.nn.conv2d(input=x, filters=tf.reshape(ar1, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1),\n",
    "                                padding=self.pad)\n",
    "            par4 = tfa.image.rotate(par3, self.ang[1] * self.rds, interpolation='BILINEAR')\n",
    "\n",
    "            if self.un_rotate:\n",
    "                out = tf.concat([par2, par4], axis=3)\n",
    "            else:\n",
    "                out = tf.concat([par1, par3], axis=3)\n",
    "\n",
    "            for aa in range(2, self.phi):\n",
    "                ar = (tf.cos(self.ang[aa] * self.rds) * arx) + (tf.sin(self.ang[aa] * self.rds) * ary)\n",
    "                partial = tf.nn.conv2d(input=x, filters=tf.reshape(ar, (self.ks, self.ks, self.nf, 1)), strides=(1, 1, 1, 1),\n",
    "                                       padding=self.pad)\n",
    "                partial2 = tfa.image.rotate(partial, self.ang[aa] * self.rds, interpolation='BILINEAR')\n",
    "                if self.un_rotate:\n",
    "                    out = tf.concat([out, partial2], axis=3)\n",
    "                else:\n",
    "                    out = tf.concat([out, partial], axis=3)\n",
    "            out_fn = tf.reshape(out, shape=(-1, self.height, self.width, self.phi, 1))\n",
    "            out_fn = tf.transpose(a=out_fn, perm=(0, 3, 1, 2, 4))\n",
    "\n",
    "            out_final = tf.concat([out_final, out_fn], axis=4)\n",
    "\n",
    "        return out_final\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(Rig2DConv, self).get_config()\n",
    "        base_config['filters'] = self.filters\n",
    "        base_config['kernel_size'] = self.kernel_size\n",
    "        base_config['phi'] = self.phi\n",
    "        return base_config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A cyclic convolution can be implemented with a linear convolution over a periodically padded feature space\n",
    "class Periodic_Pad(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Periodic_Pad, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Periodic_Pad, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.concat([inputs, inputs], axis=1)\n",
    "        return x[:, :-1, :, :, :]\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(Periodic_Pad, self).get_config()\n",
    "        return base_config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image size\n",
    "ROWS = 28\n",
    "COLS = 28\n",
    "\n",
    "# Angular samples (PHI)\n",
    "PHI = 16\n",
    "\n",
    "# Number of filters for each convolution stage\n",
    "CONV1_F = 16\n",
    "CONV2_F = 16\n",
    "CONV3_F = 16\n",
    "\n",
    "# Model definition\n",
    "in_shape = tf.keras.Input(shape=(ROWS, COLS, 1), name=\"Input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Rig2DConv(filters=1, kernel_size=10, phi=PHI, un_rotate=True, name=\"Rig\")(in_shape)\n",
    "# Periodic padding for cyclic convolution\n",
    "x = Periodic_Pad()(x)\n",
    "\n",
    "# 3 stacked convolutional predictors with batch normalization\n",
    "x = tf.keras.layers.BatchNormalization(name=\"BN1\")(x)\n",
    "x = tf.keras.layers.Conv3D(CONV1_F, kernel_size=(1, 5, 5), activation='relu', name=\"CONV1\")(x)\n",
    "x = tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), name=\"MP1\")(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization(name=\"BN2\")(x)\n",
    "x = tf.keras.layers.Conv3D(CONV2_F, kernel_size=(1, 3, 3), activation='relu', name=\"CONV2\")(x)\n",
    "x = tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2), name=\"MP2\")(x)\n",
    "\n",
    "# Translational convolution over the depth axis of the feature space\n",
    "x = tf.keras.layers.BatchNormalization(name=\"BN3\")(x)\n",
    "x = tf.keras.layers.Conv3D(CONV3_F, kernel_size=(PHI, 3, 3), activation='relu', name=\"CONV3\")(x)\n",
    "\n",
    "# Dense hidden layer predictor\n",
    "x = tf.keras.layers.Reshape((PHI, 3*3*CONV3_F))(x)\n",
    "x = tf.keras.layers.Dense(30, activation='relu', name=\"Hidden_Dense\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Dense(10, activation='softmax', name=\"Output_table\")(x)\n",
    "\n",
    "# Maxpooling applied to the columns results in the predicted class\n",
    "number = tf.keras.layers.GlobalMaxPooling1D(name=\"number\")(x)\n",
    "x_permuted = tf.keras.layers.Permute((2, 1))(x)\n",
    "# Maxpooling applied to the rows results in the predicted angle row index\n",
    "angle = tf.keras.layers.GlobalMaxPooling1D(name=\"angle\")(x_permuted)\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "model = tf.keras.Model(inputs=in_shape, outputs=number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "Rig (Rig2DConv)              (None, 16, 28, 28, 1)     3         \n",
      "_________________________________________________________________\n",
      "periodic__pad (Periodic_Pad) (None, 31, 28, 28, 1)     0         \n",
      "_________________________________________________________________\n",
      "BN1 (BatchNormalization)     (None, 31, 28, 28, 1)     4         \n",
      "_________________________________________________________________\n",
      "CONV1 (Conv3D)               (None, 31, 24, 24, 16)    416       \n",
      "_________________________________________________________________\n",
      "MP1 (MaxPooling3D)           (None, 31, 12, 12, 16)    0         \n",
      "_________________________________________________________________\n",
      "BN2 (BatchNormalization)     (None, 31, 12, 12, 16)    64        \n",
      "_________________________________________________________________\n",
      "CONV2 (Conv3D)               (None, 31, 10, 10, 16)    2320      \n",
      "_________________________________________________________________\n",
      "MP2 (MaxPooling3D)           (None, 31, 5, 5, 16)      0         \n",
      "_________________________________________________________________\n",
      "BN3 (BatchNormalization)     (None, 31, 5, 5, 16)      64        \n",
      "_________________________________________________________________\n",
      "CONV3 (Conv3D)               (None, 16, 3, 3, 16)      36880     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 144)           0         \n",
      "_________________________________________________________________\n",
      "Hidden_Dense (Dense)         (None, 16, 30)            4350      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 30)            0         \n",
      "_________________________________________________________________\n",
      "Output_table (Dense)         (None, 16, 10)            310       \n",
      "_________________________________________________________________\n",
      "number (GlobalMaxPooling1D)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 44,411\n",
      "Trainable params: 44,345\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training section\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
     ]
    }
   ],
   "source": [
    "name = f'URT_REDNN_{PHI}'\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(name + '.h5', verbose=1, save_best_only=True, monitor='val_loss', mode='min')\n",
    "tensorboardcb = tf.keras.callbacks.TensorBoard(log_dir=os.path.join('tests', name), write_images=True, write_grads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  3/469 [..............................] - ETA: 41:33 - loss: 2.4191 - accuracy: 0.1250 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e40a4ec004d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(x_train, y_train,\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kenneth hansen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kenneth hansen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kenneth hansen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kenneth hansen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kenneth hansen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\kenneth hansen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kenneth hansen\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=3,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[reduce_lr, checkpoint, tensorboardcb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
