{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mlp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padImage(image, pixels=5):\n",
    "    bottom = image[-pixels:]\n",
    "    top = image[:pixels]\n",
    "\n",
    "    img = np.insert(image, 0, bottom, 0)\n",
    "    img = np.insert(img, len(img), top, 0)\n",
    "    img = np.insert(img, [0], [0] * pixels, 1)\n",
    "    img = np.insert(img, [-1], [0] * pixels, 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = (train_images / 255.0).astype(np.float32), test_images.astype(np.float32) / 255.0\n",
    "test = np.loadtxt('mnist_rotation_new/mnist_all_rotation_normalized_float_test.amat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THE PAD HAS TO BE DONE IN THE\n",
    "### POLAR SPACE\n",
    "\n",
    "# 20 is the ceiling of (14 * sqrt(2))\n",
    "X_train_polar = [cv.linearPolar(x, tuple(np.array(x.shape)/2), 20, cv.WARP_FILL_OUTLIERS) for x in train_images]\n",
    "X_train_polar = [padImage(x, pixels=5) for x in X_train_polar]\n",
    "X_train_polar = np.array(X_train_polar)[...,None]\n",
    "\n",
    "X_test_polar = [cv.linearPolar(x, tuple(np.array(x.shape)/2), 20, cv.WARP_FILL_OUTLIERS) for x in test_images]\n",
    "X_test_polar = [padImage(x, pixels=5) for x in X_test_polar]\n",
    "X_test_polar = np.array(X_test_polar)[...,None]\n",
    "\n",
    "# Rotate test set\n",
    "X_test_r_polar = [tfa.image.rotate(x, np.random.uniform(-np.pi/2., np.pi/2.)).numpy() for x in test_images]\n",
    "X_test_r_polar = [cv.linearPolar(x, tuple(np.array(x.shape)/2), 20, cv.WARP_FILL_OUTLIERS) for x in X_test_r_polar]\n",
    "X_test_r_polar = [padImage(x, pixels=5) for x in X_test_r_polar]\n",
    "X_test_r_polar = np.array(X_test_r_polar)[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logic so far:\n",
    "# Trying Pool1D on the columns as polar is invariant horizontally, but varies on the y-axis wrt. rotations\n",
    "inputs = tf.keras.Input(shape=(38, 38, 1))\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.LayerNormalization(axis=-1, epsilon=0.001, center=True, scale=True)(x)\n",
    "x = layers.Dropout(rate=0.5)(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.LayerNormalization(axis=-1, epsilon=0.001, center=True, scale=True)(x)\n",
    "x = layers.Dropout(rate=0.5)(x)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "#x = layers.GlobalMaxPool2D()(x) \n",
    "\n",
    "### First approach - using: tf.math.reduce_max() => Flatten\n",
    "# global max pool on the col - axis = 1 (from interpretation below)\n",
    "x = tf.math.reduce_max(x, axis=1, keepdims=True)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "### Second approach - using: Transpose => GlobalMaxPooling1D => Flatten\n",
    "#x = tf.transpose(x, (2, 1, 0, 3)) # change to: c,r,batch_s,filters\n",
    "#x = layers.GlobalMaxPool1D()(x)  # Gives error here\n",
    "#x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(64, activation='linear')(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_x = models.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 38, 38, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 36, 36, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "layer_normalization_30 (Laye (None, 18, 18, 32)        64        \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "layer_normalization_31 (Laye (None, 8, 8, 64)          128       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_max_7 (TFOpLa (None, 1, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                49216     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 142,730\n",
      "Trainable params: 142,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_x.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 51s 108ms/step - loss: 1.0910 - accuracy: 0.6378 - val_loss: 0.5712 - val_accuracy: 0.8365\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.57116, saving model to col_pool.h5\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 50s 107ms/step - loss: 0.1815 - accuracy: 0.9443 - val_loss: 0.7110 - val_accuracy: 0.8011\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.57116\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 49s 104ms/step - loss: 0.1307 - accuracy: 0.9598 - val_loss: 0.5233 - val_accuracy: 0.8439\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.57116 to 0.52332, saving model to col_pool.h5\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 47s 101ms/step - loss: 0.1147 - accuracy: 0.9645 - val_loss: 0.5915 - val_accuracy: 0.8287\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.52332\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 47s 101ms/step - loss: 0.0994 - accuracy: 0.9695 - val_loss: 0.6212 - val_accuracy: 0.8298\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.52332\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 49s 105ms/step - loss: 0.0860 - accuracy: 0.9732 - val_loss: 0.4714 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.52332 to 0.47136, saving model to col_pool.h5\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 50s 107ms/step - loss: 0.0760 - accuracy: 0.9763 - val_loss: 0.4686 - val_accuracy: 0.8746\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.47136 to 0.46858, saving model to col_pool.h5\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 49s 106ms/step - loss: 0.0726 - accuracy: 0.9781 - val_loss: 0.4627 - val_accuracy: 0.8576\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.46858 to 0.46271, saving model to col_pool.h5\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 50s 106ms/step - loss: 0.0677 - accuracy: 0.9799 - val_loss: 0.5214 - val_accuracy: 0.8467\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.46271\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 49s 104ms/step - loss: 0.0664 - accuracy: 0.9788 - val_loss: 0.5305 - val_accuracy: 0.8484\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.46271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa79e0a79d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'col_pool'\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(name + '.h5', verbose=1, save_best_only=True, monitor='val_loss', mode='min')\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.000, patience=5, verbose=1,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "\n",
    "model_x.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_x.fit(X_train_polar, train_labels, batch_size=128, epochs=10, \n",
    "          validation_data=(X_test_r_polar, test_labels),\n",
    "          callbacks=[reduce_lr, checkpoint, es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration that the first k, will be the column interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       " array([[1, 2, 3],\n",
       "        [1, 2, 3],\n",
       "        [1, 2, 3]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3], [1,2,3], [1,2,3]])\n",
    "a, tf.reduce_max(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa79dfee700>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6_lab",
   "language": "python",
   "name": "p6_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
