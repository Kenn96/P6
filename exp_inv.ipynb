{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mlp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padImage(image, pixels=5):\n",
    "    bottom = image[-pixels:]\n",
    "    top = image[:pixels]\n",
    "\n",
    "    img = np.insert(image, 0, bottom, 0)\n",
    "    img = np.insert(img, len(img), top, 0)\n",
    "    img = np.insert(img, [0], [0] * pixels, 1)\n",
    "    img = np.insert(img, [-1], [0] * pixels, 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = (train_images / 255.0).astype(np.float32), test_images.astype(np.float32) / 255.0\n",
    "test = np.loadtxt('mnist_rotation_new/mnist_all_rotation_normalized_float_test.amat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THE PAD HAS TO BE DONE IN THE\n",
    "### POLAR SPACE\n",
    "\n",
    "# 20 is the ceiling of (14 * sqrt(2))\n",
    "X_train_polar = [cv.linearPolar(x, tuple(np.array(x.shape)/2), 20, cv.WARP_FILL_OUTLIERS) for x in train_images]\n",
    "X_train_polar = [padImage(x, pixels=5) for x in X_train_polar]\n",
    "X_train_polar = np.array(X_train_polar)[...,None]\n",
    "\n",
    "X_test_polar = [cv.linearPolar(x, tuple(np.array(x.shape)/2), 20, cv.WARP_FILL_OUTLIERS) for x in test_images]\n",
    "X_test_polar = [padImage(x, pixels=5) for x in X_test_polar]\n",
    "X_test_polar = np.array(X_test_polar)[...,None]\n",
    "\n",
    "# Rotate test set\n",
    "X_test_r_polar = [tfa.image.rotate(x, np.random.uniform(-np.pi/2., np.pi/2.)).numpy() for x in test_images]\n",
    "X_test_r_polar = [cv.linearPolar(x, tuple(np.array(x.shape)/2), 20, cv.WARP_FILL_OUTLIERS) for x in X_test_r_polar]\n",
    "X_test_r_polar = [padImage(x, pixels=5) for x in X_test_r_polar]\n",
    "X_test_r_polar = np.array(X_test_r_polar)[...,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_polar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6d77c44d199a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_polar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_polar' is not defined"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Input(shape=X_train_polar.shape[1:]))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.LayerNormalization(axis=-1, epsilon=0.001, center=True, scale=True))\n",
    "model.add(layers.Dropout(rate=0.5))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.LayerNormalization(axis=-1, epsilon=0.001, center=True, scale=True))\n",
    "model.add(layers.Dropout(rate=0.5))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "model.add(layers.Dense(64, activation='linear'))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001)\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(name + '.h5', verbose=1, save_best_only=True, monitor='val_loss', mode='min')\n",
    "# es = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_loss', min_delta=0.000, patience=10, verbose=1,\n",
    "#     mode='auto', baseline=None, restore_best_weights=False\n",
    "# )\n",
    "\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "# times = timecallback()\n",
    "\n",
    "# model.fit(X_train_polar, train_labels, batch_size=128, epochs=100, \n",
    "#           validation_data=(X_test_r_polar, test_labels),\n",
    "#           callbacks=[reduce_lr, checkpoint, es, times])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class timecallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.epochs = []\n",
    "        # use this value as reference to calculate cummulative time taken\n",
    "        self.timetaken = tf.timestamp()\n",
    "    def on_epoch_end(self,epoch,logs = {}):\n",
    "        self.times.append(tf.timestamp() - self.timetaken)\n",
    "        self.epochs.append(epoch)\n",
    "    def on_train_end(self,logs = {}):\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Total time taken until an epoch in seconds')\n",
    "        plt.plot(self.epochs, self.times, 'ro')\n",
    "        for i in range(len(self.epochs)):\n",
    "          j = self.times[i].numpy()\n",
    "          if i == 0:\n",
    "            plt.text(i, j, str(round(j, 3)))\n",
    "          else:\n",
    "            j_prev = self.times[i-1].numpy()\n",
    "            plt.text(i, j, str(round(j-j_prev, 3)))\n",
    "        #plt.savefig(datetime.now().strftime(\"%Y%m%d%H%M%S\") + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class wise accuracy dist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_acc = []\n",
    "preds_dict = {}\n",
    "for i in range(10):\n",
    "    preds_dict[i] = m.predict(X_test_r_polar[np.where(test_labels==i)]).argmax(axis=1)\n",
    "    class_acc.append(np.mean(preds_dict[i] == \\\n",
    "          test_labels[np.where(test_labels==i)])*100)\n",
    "class_acc = np.asarray(class_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([98.67346939, 98.41409692, 92.34496124, 93.96039604, 91.03869654,\n",
       "       86.43497758, 73.9039666 , 71.9844358 , 91.99178645, 70.96134787])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.26548344968012"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(class_acc[np.where(class_acc >= 75)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 11, 1: 1, 2: 7, 3: 9, 4: 7, 5: 119, 6: 708, 7: 8, 8: 2, 9: 86}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(preds_dict[6], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to train just load model\n",
    "name = 'm_pol_mnist_layerAdjust'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.3 87.11\n"
     ]
    }
   ],
   "source": [
    "# Plain accuracy\n",
    "m = tf.keras.models.load_model(name+'.h5')\n",
    "accuracy = np.mean(m.predict(X_test_polar).argmax(axis=1) == test_labels)*100\n",
    "# \"Rotated\" accuracy\n",
    "accuracy_rotated = np.mean(m.predict(X_test_r_polar).argmax(axis=1) == test_labels)*100\n",
    "\n",
    "print(accuracy, accuracy_rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute 12 angles (30 deg.) for each image in test image and store/load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2f = models.Model(m.inputs, m.layers[-3].output)\n",
    "# all elements in the test, and every 12 degrees, should have 30* all elements in the set\n",
    "# save them acording to the degrees, 30 degrees, 30 files, each file contains 10000*64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 360/12 = 30\n",
    "samplings = 12\n",
    "rad_d30 = (30/360)*(2*np.pi)\n",
    "a = [i * rad_d30 for i in range(360//30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_images(images, angle, pad_pixels=5):\n",
    "    processed_imgs = [tfa.image.rotate(x, angle).numpy() for x in images]\n",
    "    processed_imgs = [cv.linearPolar(x, tuple(np.array(x.shape)/2), 20, cv.WARP_FILL_OUTLIERS) for x in processed_imgs]\n",
    "    processed_imgs = [padImage(x, pixels=pad_pixels) for x in processed_imgs]\n",
    "    processed_imgs = np.array(processed_imgs)[...,None]\n",
    "    return processed_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_file = True\n",
    "file_name = 'all_MNIST_test_imgs_12samples_30deg_relu_activations.npz'\n",
    "if not have_file:\n",
    "    angle_preds = []\n",
    "    for i in range(samplings):\n",
    "        imgs = prep_images(test_images, a[i], pad_pixels=5)\n",
    "        angle_preds.append(model2f.predict(imgs))\n",
    "    angle_preds = np.asarray(angle_preds)\n",
    "    np.savez(file_name, angle_preds)\n",
    "else:\n",
    "    angle_preds = np.load(file_name)['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing average dist. of a single images average dist. across the twelve angles, with just the distances across different images in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing for class 4\n",
    "class_idx = 4\n",
    "class_entries = np.where(test_labels == class_idx)[0]\n",
    "\n",
    "# extracting all the 4 images from each angular sample\n",
    "class_extr = angle_preds[:,[class_entries]]\n",
    "class_extr = np.reshape(class_extr, (samplings, len(class_entries), 64))\n",
    "# checking if extractions are correct\n",
    "for i in range(samplings):\n",
    "    if not (class_extr[i] == angle_preds[i][class_entries]).all():\n",
    "        print('not working')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing distance for each image across its 12 angular rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_12 = []\n",
    "for i in range(len(class_entries)):\n",
    "    # all angles for a single image / 64 activations instead of 1\n",
    "    pred = class_extr[:, i]\n",
    "    d = np.sum((pred[:,None] - pred[None])**2, axis=-1)\n",
    "    d = np.maximum(d, 0)**.5\n",
    "    n = pred.shape[0]\n",
    "    class_12.append(np.sum(d)/(n*(n-1)/2))\n",
    "class_12 = np.asarray(class_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.6958994913965735, 42.249743213876044, 42.39877411813447)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(class_12), np.average(class_12), np.median(class_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Euclidean dist. between all images in the for every class (randomly rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_all = []\n",
    "for i in range(10):\n",
    "    preds_all = model2f.predict(X_test_r_polar[np.where(test_labels == i)])\n",
    "    \n",
    "    d = np.sum((preds_all[:,None] - preds_all[None])**2, axis=-1)\n",
    "    d = np.maximum(d, 0)**.5\n",
    "    n = preds_all.shape[0]\n",
    "    class_all.append(np.sum(d)/(n*(n-1)/2))\n",
    "class_all = np.asarray(class_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44.01405432, 36.69566852, 56.40035639, 56.16089649, 53.60868726,\n",
       "       54.38765835, 59.14449949, 54.38713491, 54.93994948, 56.02892617])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6_lab",
   "language": "python",
   "name": "p6_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
